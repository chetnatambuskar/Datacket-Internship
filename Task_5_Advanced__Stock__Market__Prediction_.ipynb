{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 5_Advanced_ Stock_ Market_ Prediction .ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNFfQ3ZJW5bylH5Kf4sJ3qs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chetnatambuskar/Datacket-Internship/blob/main/Task_5_Advanced__Stock__Market__Prediction_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej3GuemrMXAN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import datetime as dt\n",
        "import pandas_datareader as web"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/TATAMOTORS.NS.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "EDRgtYUWMoEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Close', fontsize=12)\n",
        "plt.plot(data.Date, data.Close,color='red')"
      ],
      "metadata": {
        "id": "87YFDED7OyCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Filter out the closing market price data\n",
        "close_data = data.filter(['Close'])\n",
        " \n",
        "# 2. Convert the data into array for easy evaluation\n",
        "dataset = close_data.values\n",
        " \n",
        "# 3. Scale/Normalize the data to make all values between 0 and 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(dataset)\n",
        " \n",
        "# 4. Creating training data size : 70% of the data\n",
        "training_data_len = math.ceil(len(dataset) *.7)\n",
        "train_data = scaled_data[0:training_data_len  , : ]\n",
        " \n",
        "# 5. Separating the data into x and y data\n",
        "x_train_data=[]\n",
        "y_train_data =[]\n",
        "for i in range(60,len(train_data)):\n",
        "    x_train_data=list(x_train_data)\n",
        "    y_train_data=list(y_train_data)\n",
        "    x_train_data.append(train_data[i-60:i,0])\n",
        "    y_train_data.append(train_data[i,0])\n",
        " \n",
        "    # 6. Converting the training x and y values to numpy arrays\n",
        "    x_train_data1, y_train_data1 = np.array(x_train_data), np.array(y_train_data)\n",
        " \n",
        "    # 7. Reshaping training s and y data to make the calculations easier\n",
        "    x_train_data2 = np.reshape(x_train_data1, (x_train_data1.shape[0],x_train_data1.shape[1],1))"
      ],
      "metadata": {
        "id": "ASWzQ4ZYMq9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True,input_shape=(x_train_data2.shape[1],1)))\n",
        "model.add(LSTM(units=50, return_sequences=False))\n",
        "model.add(Dense(units=25))\n",
        "model.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "UDH4E-wUO4Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(x_train_data2, y_train_data1, batch_size=1, epochs=10)\n"
      ],
      "metadata": {
        "id": "XI6-4vvDO8Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Creating a dataset for testing\n",
        "test_data = scaled_data[training_data_len - 60: , : ]\n",
        "x_test = []\n",
        "y_test =  dataset[training_data_len : , : ]\n",
        "for i in range(60,len(test_data)):\n",
        "    x_test.append(test_data[i-60:i,0])\n",
        " \n",
        "# 2.  Convert the values into arrays for easier computation\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
        " \n",
        "# 3. Making predictions on the testing data\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)"
      ],
      "metadata": {
        "id": "XtIryRBzPAUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = data[:training_data_len]\n",
        "valid = data[training_data_len:]\n",
        " \n",
        "valid['Predictions'] = predictions\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.title('Model')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close')\n",
        " \n",
        "plt.plot(train['Close'])\n",
        "plt.plot(valid[['Close', 'Predictions']])\n",
        " \n",
        "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "azUcHLbjPDpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.DataFrame(data=valid, columns=['Close','Predictions'])\n",
        "table"
      ],
      "metadata": {
        "id": "O1rWlA3hPIiz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}